services:
  agentic_ai_demo_service:
    image: ghcr.io/amperecomputingai/ampere-ai-agents:0.1.3
    build:
      context: .
      dockerfile: Dockerfile
    container_name: agentic_ai_demo_service
    depends_on:
      - ollama_for_agent_service
    restart: always
    ports:
      - "5678:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    environment:
      - NODE_ENV=development
      - N8N_BASIC_AUTH_ACTIVE=false # Disables authentication
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - N8N_USER_MANAGEMENT_DISABLED=true
      - N8N_READ_ONLY=true
      - N8N_INITIAL_SETUP_COMPLETED=true
      - N8N_LOG_LEVEL=debug
      - N8N_COMMUNITY_PACKAGES_ENABLED=true
      - N8N_UNVERIFIED_COMMUNITY_PACKAGES_ENABLED=true
      - N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE=true
    networks:
      - ai-agents-net

  ollama_for_agent_service:
    image: ghcr.io/amperecomputingai/ollama-ampere:1.0.0-ol9
    container_name: ollama_for_agent_service
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - n8n_ollama:/root/.ollama
    environment:
      - "OLLAMA_HOST=http://ollama_for_agent_service:11434"
    tty: true
    #entrypoint: ["ollama-entrypoint.sh"]
    #command: ["serve && ollama pull llama3.2:1b"]
    #entrypoint: ["/bin/bash", "-c", "ollama serve && sleep 5 && ollama pull llama3.2:1b"]
    entrypoint: "bash -c \"ollama serve & sleep 5 && ollama pull llama3.2:1b && wait\""
    networks:
      - ai-agents-net

  searxng:
    container_name: searxng
    image: docker.io/searxng/searxng:latest
    restart: unless-stopped
    networks:
      - ai-agents-net
    ports:
      #- "127.0.0.1:8081:8080"
      - "8081:8080"
      #- "0.0.0.1:8080:8080"
    volumes:
      - ./searxng:/etc/searxng:rw
      - n8n_searxng:/var/cache/searxng:rw
    environment:
     # - SEARXNG_BASE_URL=https://${SEARXNG_HOSTNAME:-localhost}/
     #- SEARXNG_BASE_URL=http://${SEARXNG_HOSTNAME:-localhost}/
     - SEARXNG_BASE_URL=http://searxng:8080
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

networks:
  ai-agents-net:
    driver: bridge

volumes:
  n8n_data: {}
  n8n_ollama: {}
  n8n_searxng: {}
